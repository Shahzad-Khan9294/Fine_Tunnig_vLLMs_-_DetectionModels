{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom training of YOLOv5s by MEDIUM:** https://medium.com/analytics-vidhya/training-a-custom-object-detection-model-with-yolo-v5-aa9974c07088"
      ],
      "metadata": {
        "id": "Qkr4jZ1GBsKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Image, Videos...etc Annotator link:** https://labelstud.io/guide/quick_start"
      ],
      "metadata": {
        "id": "lAYhk4KRynLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "json2yolo: https://github.com/ultralytics/JSON2YOLO"
      ],
      "metadata": {
        "id": "zEntb2ZP1gIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset making yolo: https://docs.ultralytics.com/datasets/detect/"
      ],
      "metadata": {
        "id": "v6M4ssOJ1gEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.ultralytics.com/tasks/detect/#why-should-i-use-ultralytics-yolo11-for-object-detection"
      ],
      "metadata": {
        "id": "YTsoBCd_1gCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training yolov5 code by DigitalOcean: https://www.digitalocean.com/community/tutorials/train-yolov5-custom-data\n",
        "\n",
        "Training yolov5 code by Roboflow: https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/"
      ],
      "metadata": {
        "id": "UB-U2xtl7GWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "TVIZLZj81f_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "rEKvdlEPCCqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517fd0a6-86ac-4490-e95c-f67c36b350c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "12.4\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "mXbPUUygO4gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_id = torch.cuda.current_device()\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(gpu_id)}\")\n",
        "    print(f\"Total Memory: {round(torch.cuda.get_device_properties(gpu_id).total_memory / (1024 ** 3), 2)} GB\")\n",
        "    print(f\"Allocated Memory: {round(torch.cuda.memory_allocated(gpu_id) / (1024 ** 3), 2)} GB\")\n",
        "    print(f\"Reserved Memory: {round(torch.cuda.memory_reserved(gpu_id) / (1024 ** 3), 2)} GB\")\n",
        "else:\n",
        "    print(\"No GPU available\")"
      ],
      "metadata": {
        "id": "SY3T7JVaO7fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "rnr7T8WNVUk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408ffb4d-4b98-4d84-a74f-e0479613fa42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.144-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.144-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov5n.pt\")  # Load a pretrained model\n",
        "\n",
        "# Train the model with your dataset\n",
        "model.train(\n",
        "    data='/content/drive/MyDrive/yolo_dataset_640/data.yaml',  # Path to your dataset\n",
        "    epochs30,\n",
        "    imgsz=640,\n",
        "    batch=1\n",
        ")"
      ],
      "metadata": {
        "id": "Wt--5Rd-yCC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RUNNING YOLOV5n ON ANACONDA PROMPT**"
      ],
      "metadata": {
        "id": "L5Pw3sUEzIB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a New Conda Environment (Optional but clean)"
      ],
      "metadata": {
        "id": "QYfqE-lmzP8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n yolov5 python=3.9 -y\n",
        "!conda activate yolov5"
      ],
      "metadata": {
        "id": "Ts0oKEdszBr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the YOLOv5 Repository"
      ],
      "metadata": {
        "id": "Hn60vH9szSe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!cd yolov5"
      ],
      "metadata": {
        "id": "91OtPJSNzBuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Requirements (with GPU support)"
      ],
      "metadata": {
        "id": "KIw85ulPzXET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "GgAKVrRQzBw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "install the correct version of GPU"
      ],
      "metadata": {
        "id": "2R51ynLQzcYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For CUDA 11.8 (common)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "TEQFUwekzBzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data.yaml file format"
      ],
      "metadata": {
        "id": "H4HsXWNj0QOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train: C:/Users/YourName/Documents/yolo_dataset/images/train\n",
        "val: C:/Users/YourName/Documents/yolo_dataset/images/val\n",
        "\n",
        "nc: 2  # number of classes\n",
        "names: ['class1', 'class2']  # replace with your class names\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "h1oOmQjyzpFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train YOLOv5n"
      ],
      "metadata": {
        "id": "NcZbmsgZzz0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 1 --epochs 30 --data data.yaml --cfg models/yolov5n.yaml --weights yolov5n.pt --device 0"
      ],
      "metadata": {
        "id": "bTcS62VbzyrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "--data C:/Users/YourName/Documents/yolo_dataset/data.yaml\n",
        "\n",
        "--data \"C:\\\\Users\\\\YourName\\\\Documents\\\\yolo_dataset\\\\data.yaml\"\n",
        "\n",
        "--data ../data.yaml"
      ],
      "metadata": {
        "id": "OQIyaJt903UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check inference for testing"
      ],
      "metadata": {
        "id": "TXMvlc360EWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --source your_image.jpg"
      ],
      "metadata": {
        "id": "39rg4sPv0DVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making Custom Yolov5s.yaml file"
      ],
      "metadata": {
        "id": "JfMXfOE-CsFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# yolov5c.yaml (custom config for 1-class detection)\n",
        "\n",
        "# number of classes\n",
        "nc: 1  #\n",
        "\n",
        "# model scaling\n",
        "depth_multiple: 0.33\n",
        "width_multiple: 0.50\n",
        "\n",
        "# anchor boxes\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# backbone\n",
        "backbone:\n",
        "  [[-1, 1, Focus, [64, 3]],    # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]], # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]], # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]], # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],# 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]], # 9\n",
        "  ]\n",
        "\n",
        "# head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # final detection layers\n",
        "  ]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Z3Rb0ERUCobU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OTHER CODE WORKS**"
      ],
      "metadata": {
        "id": "sh9zwKan1PNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cropping the images**"
      ],
      "metadata": {
        "id": "vzw5gsPZAES5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# ==== SETTINGS ====\n",
        "input_folder = '/content/drive/MyDrive/test_blob'           # Change to your input folder\n",
        "output_folder = '/content/croped_test_blob_folder'          # Folder to save processed images\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Crop ratios from left and right (e.g., 0.1 = crop 10% of width)\n",
        "crop_ratio_left = 0.257\n",
        "crop_ratio_right = 0.244\n",
        "\n",
        "# Final resize size\n",
        "final_size = (1000, 1000)\n",
        "\n",
        "# ==== PROCESS ====\n",
        "image_counter = 1  # Start naming from image_0001\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Failed to load image: {filename}\")\n",
        "            continue\n",
        "\n",
        "        height, width = img.shape[:2]\n",
        "\n",
        "        # Compute crop boundaries\n",
        "        left = int(crop_ratio_left * width)\n",
        "        right = int(width - crop_ratio_right * width)\n",
        "\n",
        "        # Crop image from left and right\n",
        "        cropped_img = img[:, left:right]\n",
        "\n",
        "        # Resize to final size\n",
        "        resized_img = cv2.resize(cropped_img, final_size)\n",
        "\n",
        "        # New sequential filename\n",
        "        new_filename = f\"image_{image_counter:04d}.jpg\"\n",
        "        output_path = os.path.join(output_folder, new_filename)\n",
        "        cv2.imwrite(output_path, resized_img)\n",
        "\n",
        "        print(f\"Processed and saved: {new_filename}\")\n",
        "        image_counter += 1\n",
        "\n",
        "print(f\"\\nAll images saved to: {output_folder}\")"
      ],
      "metadata": {
        "id": "eVpdyipwyR_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453ce688-f40d-4c3e-c565-bfbb2d93e869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved: image_0001.jpg\n",
            "Processed and saved: image_0002.jpg\n",
            "Processed and saved: image_0003.jpg\n",
            "Processed and saved: image_0004.jpg\n",
            "Processed and saved: image_0005.jpg\n",
            "Processed and saved: image_0006.jpg\n",
            "Processed and saved: image_0007.jpg\n",
            "Processed and saved: image_0008.jpg\n",
            "Processed and saved: image_0009.jpg\n",
            "Processed and saved: image_0010.jpg\n",
            "Processed and saved: image_0011.jpg\n",
            "Processed and saved: image_0012.jpg\n",
            "Processed and saved: image_0013.jpg\n",
            "Processed and saved: image_0014.jpg\n",
            "Processed and saved: image_0015.jpg\n",
            "Processed and saved: image_0016.jpg\n",
            "Processed and saved: image_0017.jpg\n",
            "Processed and saved: image_0018.jpg\n",
            "Processed and saved: image_0019.jpg\n",
            "\n",
            "All images saved to: /content/croped_test_blob_folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yolo format .txt file making**"
      ],
      "metadata": {
        "id": "TQ1oBVLVANCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Folder paths\n",
        "input_folder = '/content/croped_test_blob_folder'\n",
        "output_folder = '/content/test'\n",
        "labels_output_folder = '/content/test_labels'\n",
        "\n",
        "# Create output folders if they don't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "os.makedirs(labels_output_folder, exist_ok=True)\n",
        "\n",
        "# Blob detector settings\n",
        "params = cv2.SimpleBlobDetector_Params()\n",
        "params.filterByColor = True\n",
        "params.blobColor = 0\n",
        "params.minThreshold = 10\n",
        "params.maxThreshold = 200\n",
        "\n",
        "params.filterByArea = True\n",
        "params.minArea = 5\n",
        "params.maxArea = 50\n",
        "\n",
        "params.filterByCircularity = True\n",
        "params.minCircularity = 0.7\n",
        "\n",
        "params.filterByInertia = False\n",
        "params.filterByConvexity = False\n",
        "\n",
        "# Iterate through all images in the input folder\n",
        "for image_name in tqdm(os.listdir(input_folder)):\n",
        "    if image_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "        original_img_path = os.path.join(input_folder, image_name)\n",
        "        original_img = cv2.imread(original_img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if original_img is None:\n",
        "            continue\n",
        "\n",
        "        original_height, original_width = original_img.shape\n",
        "        resized_width, resized_height = 640, 640\n",
        "        scale_x = resized_width / original_width\n",
        "        scale_y = resized_height / original_height\n",
        "\n",
        "        detector = cv2.SimpleBlobDetector_create(params)\n",
        "        keypoints = detector.detect(original_img)\n",
        "\n",
        "        resized_img = cv2.resize(original_img, (resized_width, resized_height))\n",
        "        save_path = os.path.join(output_folder, image_name)\n",
        "        cv2.imwrite(save_path, resized_img)\n",
        "\n",
        "        # Prepare label file\n",
        "        txt_filename = os.path.splitext(image_name)[0] + '.txt'\n",
        "        txt_path = os.path.join(labels_output_folder, txt_filename)\n",
        "\n",
        "        with open(txt_path, 'w') as label_file:\n",
        "            for kp in keypoints:\n",
        "                x = kp.pt[0] * scale_x\n",
        "                y = kp.pt[1] * scale_y\n",
        "                r = (kp.size / 2.0) * ((scale_x + scale_y) / 2.0)\n",
        "\n",
        "                x_center = x / resized_width\n",
        "                y_center = y / resized_height\n",
        "                bbox_width = (2 * r) / resized_width\n",
        "                bbox_height = (2 * r) / resized_height\n",
        "\n",
        "                # Skip invalid or near-zero area boxes\n",
        "                if bbox_width <= 0.0005 or bbox_height <= 0.0005:\n",
        "                    continue\n",
        "\n",
        "                label_file.write(f\"1 {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\")\n",
        "\n",
        "print(f\"Saved YOLO annotations to {labels_output_folder}\")"
      ],
      "metadata": {
        "id": "5sqHvDnsVNrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea44b97-2581-4627-c557-36561fd27df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:06<00:00,  3.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved YOLO annotations to /content/test_labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deleting the specific folder from colab env**"
      ],
      "metadata": {
        "id": "MYLU5GZh1g-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the folder you want to delete\n",
        "folder_path = '/content/sample_data/yolo_dataset/labels/train_labels'  # Replace with your folder path\n",
        "\n",
        "# Delete the folder and all its contents\n",
        "shutil.rmtree(folder_path)\n",
        "\n",
        "print(f\"Folder '{folder_path}' and its contents have been deleted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3fHlcB1QXOl",
        "outputId": "035295b3-833c-4745-a941-30e410fb90bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/sample_data/yolo_dataset/labels/train_labels' and its contents have been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count images in a folder**"
      ],
      "metadata": {
        "id": "M1Nb_pig1rdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Folder path where the images are stored\n",
        "folder_path = '/content/train'  # Replace with your folder path\n",
        "\n",
        "# Image extensions to look for\n",
        "image_extensions = ('.jpg', '.jpeg', '.png')\n",
        "\n",
        "# Count the images in the folder\n",
        "image_count = 0\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(image_extensions):\n",
        "        image_count += 1\n",
        "\n",
        "print(f\"Total number of images in the folder: {image_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14f82DiQPUpA",
        "outputId": "e76eb4dd-ddc7-436a-d00c-fd3c66c67e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images in the folder: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting the 1 into 0 in the .txt files in yolo dataset**"
      ],
      "metadata": {
        "id": "96Cji1h11xEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Folder path containing the text files\n",
        "folder_path = '/content/drive/MyDrive/yolo_dataset_640/labels/test'  # Replace with your folder path\n",
        "\n",
        "# Iterate over all files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.txt'):  # Process only .txt files\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Open and read the text file\n",
        "        with open(file_path, 'r') as file:\n",
        "            file_content = file.read()\n",
        "\n",
        "        # Replace '1' with '0' in the content\n",
        "        updated_content = file_content.replace('1', '0')\n",
        "\n",
        "        # Write the updated content back to the file\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.write(updated_content)\n",
        "\n",
        "        print(f\"Updated: {filename}\")\n",
        "\n",
        "print(\"All text files have been processed.\")"
      ],
      "metadata": {
        "id": "v9Y2Ir4TQriJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f518a7f7-2047-4448-e959-7619cb37467e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated: image_0002.txt\n",
            "Updated: image_0010.txt\n",
            "Updated: image_0007.txt\n",
            "Updated: image_0013.txt\n",
            "Updated: image_0001.txt\n",
            "Updated: image_0005.txt\n",
            "Updated: image_0017.txt\n",
            "Updated: image_0011.txt\n",
            "Updated: image_0016.txt\n",
            "Updated: image_0019.txt\n",
            "Updated: image_0004.txt\n",
            "Updated: image_0006.txt\n",
            "Updated: image_0015.txt\n",
            "Updated: image_0014.txt\n",
            "Updated: image_0008.txt\n",
            "Updated: image_0018.txt\n",
            "Updated: image_0003.txt\n",
            "Updated: image_0009.txt\n",
            "Updated: image_0012.txt\n",
            "All text files have been processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ByWMYu4xSUB9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}